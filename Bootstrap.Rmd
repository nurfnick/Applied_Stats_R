---
title: "Bootstrapping and Cross Validation"
author: "Nicholas Jacob"
date: "11/15/2020"
output: html_document
---

```{r setup, include = FALSE}
library(ggplot2)
library(ggExtra)
library(tidyverse)
library(GGally)
library(boot)
library(caret)
data = read.csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSDpJqmVSks0f4vLzzcmcTfPJ8TSu4ziCNpTFy_fIY6LibZksRXzCfJYXj9qZd4NiofejxoYSkmLMwu/pub?output=csv')

```

# Bootstrapping

Next we will take the same data and explore the bootstrapping method.  Many of you were introduced to this in Intro to Stats.  I'll repeat my hypothesis test that the mean ages of men and women olympic athletes are different.  If we establish the mean age of men and women olympians as $\mu_M$ and $\mu_W$ respectively, our null and alternative hypothesis will be:

$$
\begin{align}
H_0:\ \mu_M=\mu_W\\
H_A:\ \mu_M\neq\mu_W.
\end{align}
$$
I have added the library **boot** to my packages that I load at the beginning of the document and I'll **set.seed**, there is nothing special about the number you pick, if you change it you'll get another random, but repeatable action.  Any Douglas Adams fans know why I use 42?  In order to run the boot command you have to pass it a function that can be sub-divided.  Essentially you just have to pass it a function that slices the dataset.  Mimic what I do below and you should be golden!


```{r bootFullMean}
set.seed(42)
samp_mean <- function(x, i) {
  mean(x[i])
}
ages <- na.omit(data$Age) #needed to get rid of the NaN's
results <- boot(ages, samp_mean, 100)
plot(results)
```
```{r}
boot.ci(results, type="perc")
```
Let's repeat this but first divide the data based on Sex.
```{r}
menages <- na.omit(data[which(data$Sex == 'M'),'Age'])
womenages <- na.omit(data[which(data$Sex == 'F'),'Age'])
bootM <- boot(menages, samp_mean,100)
bootW <- boot(womenages, samp_mean, 100)
boot.ci(bootM, type = 'perc')
```
```{r}
boot.ci(bootW, type = 'perc')
```

We notice that the center of both confidence intervals fall outside of the other so we will reject the null hypothesis.  The mean age of men and women are different.

Let's look at a non-parametric statistic.  I am going to ask if the median age of winter athletes is different from summer athletes.

```{r}
winterAge <- na.omit(data[which(data$Season== 'Winter'),'Age'])
summerAge <- na.omit(data[which(data$Season== 'Summer'),'Age'])
median(winterAge)
```
```{r}
median(summerAge)
```

Well they both have the same sample median so I doubt they will be different but let's test it anyway.
$$
H_0; m_S=m_W\\
H_A: m_S\neq m_W
$$
```{r}
samp_median <- function(x,i){
  median(x[i])
}

bootW = boot(winterAge,samp_median,100)
boot.ci(bootW, type = 'perc')
```

```{r}
bootS = boot(summerAge, samp_median,100)
boot.ci(bootS, type = 'perc')
```

Since the Confidence intervals are the same, we will fail to reject the null hypothesis.  Thus we do not have evidence to suggest that the median age of winter and summer athletes is different.  It might have been best to do the median age of men and women but sometimes I just like to explore.  I should also note that in science a fail to reject is almost never reported.  This is sometimes called the 'file drawer problem' in that research that yields a 'fail to reject the null hypothesis' is never reported.  This is an issue because if an erroneous experiment is repeated 20 times, 19 of these will fail to reject but the one that does reject the null hypothesis will be published.  Sometimes this is also referred to as the reproducibility crisis.  It is a big problem in the social science literature!

# Cross Validation

I'd like to do cross validation in two ways.  I am first going to do the traditional split, 66%.  I'll fit the model to the training data and then check out the results on the remaining 34% testing data.

```{r}
trainingSamples <- createDataPartition(data$ID,p=.66,list = FALSE)
trainData <- data[trainingSamples,]
testData <- data[-trainingSamples,]

model <- lm(Age ~ Sport + Height + Weight, data = trainData)
summary(model)
```

I specifically picked a silly model.  Does anybody think we can predict the age of an athlete by their sport, height or weight?  You should notice though many of the coefficients are statistically significant.  Let's check out how this does on the testing data.

```{r}
predict(model,testData)
```